<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>

<head>
<title>Homepage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<link rel="stylesheet" type="text/css" href="css/style.css" />
<script type="text/javascript" src="js/jquery-1.7.js"></script>
<script type="text/javascript" src="js/jcarousellite_1.0.1.min.js"></script>
<!--[if IE 6]> <link rel="stylesheet" type="text/css" href="css/ie.css" /> <![endif]-->
<script type="text/javascript">
$(function() {
    $(".gallery").jCarouselLite({
        btnNext: ".next",
        btnPrev: ".prev"
    });
});
</script>
</head>
<body>

<div id="leftcont">
	<div id="leftimg"><a title="home" href="index.html"><img alt="image description" src="images/profile.jpg" /></a></div>
	<div id="menu">
		<ul>
			<li><a title="link one" href="index.html">Home</a></li>
			<li><a title="link two" href="publication.html">Publications</a></li>
      <li><a title="link three" href="teaching.html">Teaching</a></li>
			<li><a title="link four" href="project.html">Projects</a></li>
		</ul>
	</div>
  <div id="menu1">
    <ul>
      <li><a title="link four" href="KGSum.html">KGSum</a></li>
      <li><a title="link five" href="AnsW.html">AnsW</a></li>
      <li><a title="link six" href="TGNet.html">TGNet</a></li>
      <li><a title="link six" href="GRIP.html">GRIP</a></li>
    </ul>
  </div>
  <div id="menu">
    <ul>
      <li><a href="Files/songqi-en.pdf">Biography</a></li>
    </ul>
  </div>
</div>

<div id="main">
	<div id="social"> 
	<a href="https://twitter.com/Leo_Qi1990"> <img src="images/twitter.png" alt="" />  </a>
	<a href="https://github.com/songqi1990"> <img src="images/github.png" alt="" /></a>
	<a href="https://www.linkedin.com/in/qi-song-7b406940/"> <img src="images/linkedin.png" alt="" /></a>
	</div> 
	<div class="clr"></div>
	<h1>Ranking Nodes in Temporal Graphs</h1>
    
    <p>QNode ranking in temporal networks are often impacted by heterogeneous context from node content, temporal, and structural di- mensions. This project introduces TGNet, a deep learning framework for node ranking in heterogeneous temporal graphs. TGNet utilizes a variant of Recurrent Neural Network to adapt context evolution and extract context features for nodes. It incorporates a novel influence network to dynamically estimate temporal and structural influence among nodes over time. To cope with label sparsity, it integrates graph smoothness constraints as a weak form of supervision. We show that the application of TGNet is feasible for large-scale networks by developing efficient learning and inference algorithms with optimization techniques. Using real-life data, we experimentally verify the effectiveness and efficiency of TGNet techniques. We also show that TGNet yields intuitive explanations for applications such as alert detection and academic impact rank- ing, as verified by our case study.</p>

    <h2> Why Ranking Nodes in Temporal Graphs is Different From in Static Graphs? </h2>
	<p> Temporal graphs have been widely applied to model dynamic networks. A temporal graph is a sequence of graph snapshots, where each snapshot (G,t) encodes a graph G occurs at an associated timestamp t. Emerging applications call for efficient predictive models that can effectively suggest and maintain the nodes with high priority in dynamic networks. The need for such models is evident in causal analysis, anomaly and attack detection, and link prediction in social networks. <br>
	Learning to rank node in static graphs has been studied. A common practice in prior work is to make use of latent features from graph structures to learn ranking functions. Learning node ranks in dynamic networks are nevertheless more involved than its counterpart in static networks. In particular, the node ranks can be influenced by rich context from heterogeneous node information, network structures, and temporal perspectives.</p>

	<center><img src="images/TGNet_example.png" alt="TGNet Example" height="240" align="middle"/></center>
	<br>

	<p> While desirable, learning to rank nodes in temporal graphs is more challenging than its counterpart over static graphs.
		<ul>
			<li>
				<U>Context learning.</U> Context features of a node are formed by cer- tain activities related to this node. Such features offer us impor- tant sources of information to differentiate the roles that different nodes play in node ranking. In temporal graphs, context features are characterized from both structural and temporal dimensions.
			</li>
			<li>
				<U>Context dynamics.</U> Context features of a node bear constant changes over time. Such dynamics require effective and expressive models that can capture context evolution over time.
			</li>
			<li>
				<U>Label sparsity.</U> Labels provided by users are typically sparse and cover a small fraction of nodes. For example, system admins and anti-malware software may only provide a few ranked examples over months of data with thousands of alerts. This calls for effective learning that can be generalized from sparsely labeled data.
			</li>
			<li>
				<U>Time cost.</U> Efficient algorithms should be developed to support fast learning and ranking upon the arrival of new nodes. This requires effective optimization and provable performance guarantees for both learning and inference cost.
			</li>
		</ul>
	</p>

	<h2> Overview of TGNet Model. </h2>
	<p>Reduced summaries can be used in knowledge search, query suggestion and fact checking in knowledge graphs.
		<ul>
			<li>
				<U>Initialization layer</U>: projects input feature vector into hidden state space;
			</li>		
			<li>
				<U>Structural propagation layer</U>: exchanges neighborhood information in a snapshot; 
			</li>
			<li>
				<U>Temporal propagation layer</U>: propagates temporal influence between snapshots; 
			</li>
			<li>
				<U>Output layer</U>: transforms hidden states to ranking scores. 
			</li>
		</ul>
	</p>

	<center><img src="images/TGNet_model.png" alt="TGNet model" height="220" align="middle"/></center>
	<center><img src="images/TGNet_layer.png" alt="TGNet layer" height="250" align="middle"/></center>

	<h2> Make the Model More Efficient?</h2>
	<p>We introduce influence network, a novel network layer utilized by TGNet to cope with context dynamics. Unlike conventional methods that adopt fixed pairwise influence influence network layer takes updated node context features as input, and dynamically estimates the amount of temporal and structural influence among the nodes.<br>
	<U>“Node-centric” vs. “Edge-centric”.</U> Conventional methods adopts “edge-centric” influence model, where the parameters are associated to edges. Nevertheless, the assumption of fixed edge influence is hard to hold for context changes. Moreover, it is daunting for users to choose edge types with expected generalization power for unknown testing data. In contrast, TGNet adopts an influence network layer, denoted as InfNet, which uses a “node-centric” approach to model influence. The layer InfNet is devised based on two intuitions: (1) The influence between two nodes is conditioned by their contexts; and (2) The node context is determined by its hidden state. 
	</p>

	<center><img src="images/TGNet_Infe.png" alt="TGNet inference" height="150" align="middle"/></center>

	<h2>Training the Model</h2>
	<p>Given labeled data, we introduce an end-to-end training algorithm that jointly learns the model parameters.</p>

	<center><img src="images/TGNet_loss.png" alt="TGNet loss function" height="250" align="middle"/></center>


	<h2>Datasets</h2>
	<p>
		We conducted experiments using four real-world datasets.
		<ul>
			<li>
				System Log Dataset (SLD) is a private system log dataset from NEC labs, including 30 days’ system logs generated by a cluster of 16 hosts. Using log analysis tool <a href="https://www.nipunarora.net/project/ngla/">NGLA</a>, we obtained a remporal graph and we focus on ranking alert nodes.
			</li>
			<li>
				<a href="https://www.unb.ca/cic/datasets/ids.html">ISCX Intrusion detection data (IDS)</a> is a network intrusion dataset. In this dataset, we are interested in packet node ranking: the higher one packet node is ranked, the more likely it indicates an attack.
			</li>
			<li>
				<a href="https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/">Microsoft academic graph (MAG)</a> is an academic network. We sampled 100K author ranking pairs based on their H -index value, and focus on learning to rank author nodes.
			</li>
			<li>
				<a href="https://snap.stanford.edu/data/amazon-meta.html"> Amazon product co-purchasing network (APC)</a> is a network describing the the product information and related reviews. We focus on learning to rank the salesrank value for each product and sampled 100k product pairs.
		</ul>

	<center><table border="1">
		<tr>
			<td> Datasets</td>
			<td> SLD </td>
			<td> <a href="https://www.unb.ca/cic/datasets/ids.html">IDS</a></td>
			<td> <a href="https://www.microsoft.com/en-us/research/project/microsoft-academic-graph/">MAG</a> </td>
			<td> <a href="https://snap.stanford.edu/data/amazon-meta.html">APC</a></td>
		</tr>
		<tr>
			<td># of nodes</td>
			<td>61.4K</td>
			<td>5.7M</td>
			<td>2.5M</td>
			<td>2.1M</td>
		</tr>
		<tr>
			<td># of edges</td>
			<td>258.1K</td>
			<td>11.5M</td>
			<td>16.2M</td>
			<td>9.5M</td>
		</tr>
		<tr>
			<td># of snapshots</td>
			<td>19.4K</td>
			<td>66.7K</td>
			<td>12K</td>
			<td>1.5K</td>
		</tr>
		<tr>
			<td># of training node pairs</td>
			<td>20K</td>
			<td>100K</td>
			<td>100K</td>
			<td>100K</td>
		</tr>
	</table></center>

	</p>

	<h2>Publications</h2>
        <ol>
        <li>TGNet: Learning to Rank Nodes in Temporal Graphs.&nbsp;<a href="Files/paper/CIKM2018.pdf">[Paper]</a><a href="Files/paper/CIKM2018_slide.pdf">[Slide]</a>
            <br>ACM International Conference on Information and Knowledge Management(<strong>CIKM</strong>), 2018.<br>
            <strong>Qi Song</strong>,  Bo Zong, Yinghui Wu, Lu-An Tang, Hui Zhang, Guofei Jiang and Haifeng Chen
        </li>
      </ol>

	<h2>Acknowledgements</h2>
	<p>This project was done when Qi was an intern at NEC Labs America and is supported in part by NSF IIS-1633629.</p>

</div>

</body>
</html>